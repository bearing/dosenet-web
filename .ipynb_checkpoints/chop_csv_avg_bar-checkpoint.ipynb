{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "import calendar\n",
    "import json\n",
    "from pathlib import Path\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_delta(date, delta):\n",
    "    m = date.month + delta\n",
    "    y = date.year\n",
    "    while m < 1 or m > 12:\n",
    "        if m < 1:\n",
    "            m += 12\n",
    "            y -= 1\n",
    "        else: # m > 12\n",
    "            m -= 12\n",
    "            y += 1\n",
    "    d = min(date.day, calendar.monthrange(y, m)[1])\n",
    "    return date.replace(day=d,month=m, year=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_str_to_date(str):\n",
    "    # 2020-02-25 01:57:07+00:00\n",
    "    if len(str) == 25:\n",
    "        return dt.strptime(str[:-6], \"%Y-%m-%d %H:%M:%S\")    \n",
    "    \n",
    "    # 2020-03-29 21:41:44+0000\n",
    "    elif len(str) == 24:\n",
    "        return dt.strptime(str[:-5], \"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # unknown\n",
    "    else:\n",
    "        return dt.strptime(str);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_str_to_year_month(str):\n",
    "    return str[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2020, 3, 29, 21, 41, 44)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_str_to_year_month(\"2020-03-29 21:41:44+0000\")\n",
    "format_str_to_date(\"2020-03-29 21:41:44+0000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sort(arr):\n",
    "\n",
    "    if len(arr) > 1:\n",
    "        m = len(arr) // 2\n",
    "        left = arr[:m]\n",
    "        right = arr[m:]\n",
    "        left = merge_sort(left)\n",
    "        right = merge_sort(right)\n",
    "\n",
    "        arr = []\n",
    "\n",
    "        while len(left) > 0 and len(right) > 0:\n",
    "            if left[0] < right[0]:\n",
    "                arr.append(left.pop(0))\n",
    "            else:\n",
    "                arr.append(right.pop(0))\n",
    "\n",
    "        for i in left:\n",
    "            arr.append(i)\n",
    "        for i in right:\n",
    "            arr.append(i)\n",
    "\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emptydir(directory):\n",
    "    directory = Path(directory)\n",
    "    if directory.exists():\n",
    "        for item in directory.iterdir():\n",
    "            if item.is_dir():\n",
    "                rmdir(item)\n",
    "            else:\n",
    "                item.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmdir(directory):\n",
    "    directory = Path(directory)\n",
    "    if directory.exists():\n",
    "        for item in directory.iterdir():\n",
    "            if item.is_dir():\n",
    "                rmdir(item)\n",
    "            else:\n",
    "                item.unlink()\n",
    "        directory.rmdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the meta function you call to do everything for you\n",
    "def chop_csv(file_name, date_range, month_gap=1, src_path=Path(\"\"), end_path=Path(\"\")):\n",
    "    \n",
    "    # get the data from the specified csv file\n",
    "    data = pd.read_csv(src_path / file_name)\n",
    "\n",
    "    monthly_sums = dict()\n",
    "    monthly_record_count = dict()\n",
    "    \n",
    "    date_range_unix = [date_range[0].timestamp(), date_range[1].timestamp()]\n",
    "    date_range_str = [date_range[0].strftime(\"%Y-%m\"), date_range[1].strftime(\"%Y-%m\")]\n",
    "    \n",
    "    # figure out which indexes are the right gaps\n",
    "    for i, series in data.iterrows():\n",
    "\n",
    "        date_unix = series['deviceTime_unix']\n",
    "        if date_range_unix[0] <= date_unix <= date_range_unix[1]:\n",
    "            cpm_count = series['cpm']\n",
    "            \n",
    "            year_month = format_str_to_year_month(series['deviceTime_local'])\n",
    "            if year_month in monthly_sums:\n",
    "                monthly_sums[year_month] += cpm_count\n",
    "                monthly_record_count[year_month] += 1\n",
    "            else:\n",
    "                monthly_sums[year_month] = cpm_count\n",
    "                monthly_record_count[year_month] = 1\n",
    "    \n",
    "    monthly_avgs_dict = dict()\n",
    "    for date, monthly_sum in monthly_sums.items():\n",
    "        monthly_avgs_dict[date] = monthly_sum / monthly_record_count[date]\n",
    "    \n",
    "    return monthly_avgs_dict\n",
    "        \n",
    "#     sorted_dates = merge_sort(list(monthly_avgs_dict))\n",
    "#     sorted_monthly_avgs = []\n",
    "#     for date in sorted_dates:\n",
    "# #         print(type(monthly_avgs_dict))\n",
    "#         sorted_monthly_avgs.append(monthly_avgs_dict[date])\n",
    "    \n",
    "    \n",
    "#     data_dict = {\n",
    "#         'month_local': sorted_dates,\n",
    "#         'avg_cpm': sorted_monthly_avgs\n",
    "#     }\n",
    "    \n",
    "#     df = pd.DataFrame(data_dict, columns=['month_local', 'avg_cpm'])\n",
    "\n",
    "#     end_path.mkdir(parents=True, exist_ok=True)\n",
    "#     df.to_csv(end_path / file_name, index=False)\n",
    "#     print(\"pushing averaged data to \" + file_name)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_avg(file_names, date_range, month_gap=1, src_path=Path(\"\"), end_path=Path(\"\")):\n",
    "    common_date_range = (dt(2016,10,1), dt(2018,3,1))\n",
    "    \n",
    "    # format file_names\n",
    "    file_names = [file_name + \".csv\" if file_name[-4:] != \".csv\" else file_name for file_name in file_names]\n",
    "    location_names = [file_name[:-4] if file_name[-4:] == \".csv\" else file_name for file_name in file_names]\n",
    "\n",
    "    avgs_by_location = dict()\n",
    "    \n",
    "    for file_name, location_name in zip(file_names, location_names):\n",
    "        avgs_by_location[location_name] = chop_csv(file_name, date_range, month_gap, src_path, end_path)\n",
    "        \n",
    "    avgs_by_date = dict()\n",
    "    \n",
    "    for location, location_avgs in avgs_by_location.items():\n",
    "#         print(location_avgs)\n",
    "        for date, monthly_avg in location_avgs.items():\n",
    "            if not date in avgs_by_date:\n",
    "                avgs_by_date[date] = dict()\n",
    "            avgs_by_date[date][location] = monthly_avg\n",
    "            \n",
    "#     print(avgs_by_date)\n",
    "#     print()\n",
    "#     print(\"sorted\")\n",
    "#     print()\n",
    "    \n",
    "    sorted_dates = merge_sort(list(avgs_by_date))\n",
    "    print(sorted_dates)\n",
    "    \n",
    "    csv_exports = []\n",
    "    \n",
    "    for date in sorted_dates:\n",
    "        avg_cpms = []\n",
    "        \n",
    "#         for key, val in avgs_by_date[date].items():\n",
    "#             locations.append(key)\n",
    "#             avg_cpms.append(val)\n",
    "        \n",
    "        for location in location_names:\n",
    "            if location in list(avgs_by_date[date]):\n",
    "                avg_cpms.append(avgs_by_date[date][location])\n",
    "            else:\n",
    "                avg_cpms.append(\"NaN\")\n",
    "        \n",
    "        export_dict = {\n",
    "            'location': location_names,\n",
    "            'avg_cpm': avg_cpms\n",
    "        }\n",
    "#         print()\n",
    "#         print(export_dict)\n",
    "#         print()\n",
    "        csv_exports.append(pd.DataFrame(export_dict, columns=['location', 'avg_cpm']))\n",
    "    \n",
    "    \n",
    "#     print()\n",
    "#     print(csv_exports)\n",
    "#     print()\n",
    "    \n",
    "    emptydir(end_path)\n",
    "    end_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for i, df in enumerate(csv_exports):\n",
    "        df.to_csv(end_path / (\"data_\" + str(i) + \".csv\"), index=False)\n",
    "    \n",
    "    \n",
    "    # TODO: FIX THE METADATA OUTPUT\n",
    "    \n",
    "    # add info to the metadata file.\n",
    "#     metadata = dict()\n",
    "#     try:\n",
    "#         with open(end_path / \"metadata.json\") as file:\n",
    "#             metadata = json.load(file)\n",
    "#         print(\"updating metadata.json\")\n",
    "#     except FileNotFoundError:\n",
    "#         print(\"metadata.json not found, creating new file\")\n",
    "#     except ValueError:\n",
    "#         print(\"contents of metadata.json are not formatted correctly, creating new file\")\n",
    "\n",
    "    with open(end_path / \"metadata.json\", \"w\") as file:\n",
    "        metadata = {\n",
    "            \"chart_type\": \"bar_graph\",\n",
    "            \"description\": \"insert desription of data to help people know what the data in the files is for. human read, not machine parsed.\",\n",
    "            \"file_name\": \"data\",\n",
    "            \"file_count\": len(csv_exports),\n",
    "            \"locations\": location_names,\n",
    "            \"start_date\": format_str_to_year_month(str(date_range[0])),\n",
    "            \"month_gap\": month_gap\n",
    "        }\n",
    "#         metadata[\"chart_type\"] = \"bar_graph\"\n",
    "#         metadata[\"description\"] = \"insert desription of data to help people know what the data in the files is for. human read, not machine parsed.\"\n",
    "#         metadata[\"file_name\"] = \"data\"\n",
    "#         metadata[\"file_count\"] = len(csv_exports)\n",
    "#         metadata[\"locations\"] = location_names\n",
    "#         metadata[\"start_date\"] = format_str_to_year_month(str(date_range[0]))\n",
    "#         metadata[\"\"]\n",
    "        # metadata[\"date_range\"] = [format_str_to_year_month(str(date_range[0])), format_str_to_year_month(str(date_range[1]))]\n",
    "        \n",
    "        json.dump(metadata, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2016-10', '2016-11', '2016-12', '2017-01', '2017-02', '2017-03', '2017-04', '2017-05', '2017-06', '2017-07', '2017-08', '2017-09', '2017-10', '2017-11', '2017-12', '2018-01', '2018-02', '2018-03']\n",
      "Finished formatting data in 7.0:34.73051679998753minutes.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "\n",
    "file_names = [\"alameda_hs.csv\", \"campolindo.csv\", \"foothills.csv\", \"ghs.csv\", \"harbor_bay.csv\"]\n",
    "file_names = [\"alameda_hs.csv\", \"campolindo.csv\", \"foothills.csv\", \"ghs.csv\", \"harbor_bay.csv\", \"miramonte.csv\", \"lbl.csv\", \"koriyama_ch.csv\", \"kaist.csv\", \"jlhs.csv\"]\n",
    "\n",
    "# file_names = [\"alameda_hs.csv\", \"campolindo.csv\"]\n",
    "date_range = (dt(2016,10,1), dt(2018,3,1))\n",
    "\n",
    "create_avg(file_names, date_range, end_path=Path(\"monthly_avgs\"))\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "print(\"Finished formatting data in \" + str(int((end_time - start_time) // 60)) + \":\" + str(round((end_time - start_time) % 60, 2)) + \" minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'alameda_hs.csv', 'campolindo.csv', 'foothills.csv', 'ghs.csv', 'harbor_bay.csv']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_names = [\"alameda_hs.csv\", \"campolindo.csv\", \"foothills.csv\", \"ghs.csv\", \"harbor_bay.csv\", \"a\"]\n",
    "print(sorted(file_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
